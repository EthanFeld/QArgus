{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "818ae72f",
   "metadata": {},
   "source": [
    "# MNIST-10 Quantum Counting Demo\n",
    "\n",
    "This notebook trains a small classical model, loads its weights into the\n",
    "QArgus quantum model, runs inference, and applies a quantum-counting\n",
    "style estimator to count a target digit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb72a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parents[0]\n",
    "SRC = ROOT / 'src'\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "from qargus import QuantumResNet, QuantumResNetConfig, estimate_count, run_semantic_model, model_to_qasm\n",
    "from qargus.weights import load_sklearn_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7ade1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `parser='auto'` with dense data requires pandas to be installed. Alternatively, explicitly set `parser='liac-arff'`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ethan\\.conda\\envs\\qargus\\Lib\\site-packages\\sklearn\\utils\\_optional_dependencies.py:42\u001b[39m, in \u001b[36mcheck_pandas_support\u001b[39m\u001b[34m(caller_name)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ethan\\.conda\\envs\\qargus\\Lib\\site-packages\\pandas\\__init__.py:61\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[32m     63\u001b[39m     ArrowDtype,\n\u001b[32m     64\u001b[39m     Int8Dtype,\n\u001b[32m     65\u001b[39m     Int16Dtype,\n\u001b[32m     66\u001b[39m     Int32Dtype,\n\u001b[32m     67\u001b[39m     Int64Dtype,\n\u001b[32m     68\u001b[39m     UInt8Dtype,\n\u001b[32m     69\u001b[39m     UInt16Dtype,\n\u001b[32m     70\u001b[39m     UInt32Dtype,\n\u001b[32m     71\u001b[39m     UInt64Dtype,\n\u001b[32m     72\u001b[39m     Float32Dtype,\n\u001b[32m     73\u001b[39m     Float64Dtype,\n\u001b[32m     74\u001b[39m     CategoricalDtype,\n\u001b[32m     75\u001b[39m     PeriodDtype,\n\u001b[32m     76\u001b[39m     IntervalDtype,\n\u001b[32m     77\u001b[39m     DatetimeTZDtype,\n\u001b[32m     78\u001b[39m     StringDtype,\n\u001b[32m     79\u001b[39m     BooleanDtype,\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[32m     81\u001b[39m     NA,\n\u001b[32m     82\u001b[39m     isna,\n\u001b[32m     83\u001b[39m     isnull,\n\u001b[32m     84\u001b[39m     notna,\n\u001b[32m     85\u001b[39m     notnull,\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[32m     87\u001b[39m     Index,\n\u001b[32m     88\u001b[39m     CategoricalIndex,\n\u001b[32m     89\u001b[39m     RangeIndex,\n\u001b[32m     90\u001b[39m     MultiIndex,\n\u001b[32m     91\u001b[39m     IntervalIndex,\n\u001b[32m     92\u001b[39m     TimedeltaIndex,\n\u001b[32m     93\u001b[39m     DatetimeIndex,\n\u001b[32m     94\u001b[39m     PeriodIndex,\n\u001b[32m     95\u001b[39m     IndexSlice,\n\u001b[32m     96\u001b[39m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[32m     97\u001b[39m     NaT,\n\u001b[32m     98\u001b[39m     Period,\n\u001b[32m     99\u001b[39m     period_range,\n\u001b[32m    100\u001b[39m     Timedelta,\n\u001b[32m    101\u001b[39m     timedelta_range,\n\u001b[32m    102\u001b[39m     Timestamp,\n\u001b[32m    103\u001b[39m     date_range,\n\u001b[32m    104\u001b[39m     bdate_range,\n\u001b[32m    105\u001b[39m     Interval,\n\u001b[32m    106\u001b[39m     interval_range,\n\u001b[32m    107\u001b[39m     DateOffset,\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[32m    109\u001b[39m     to_numeric,\n\u001b[32m    110\u001b[39m     to_datetime,\n\u001b[32m    111\u001b[39m     to_timedelta,\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[32m    113\u001b[39m     Flags,\n\u001b[32m    114\u001b[39m     Grouper,\n\u001b[32m    115\u001b[39m     factorize,\n\u001b[32m    116\u001b[39m     unique,\n\u001b[32m    117\u001b[39m     value_counts,\n\u001b[32m    118\u001b[39m     NamedAgg,\n\u001b[32m    119\u001b[39m     array,\n\u001b[32m    120\u001b[39m     Categorical,\n\u001b[32m    121\u001b[39m     set_eng_float_format,\n\u001b[32m    122\u001b[39m     Series,\n\u001b[32m    123\u001b[39m     DataFrame,\n\u001b[32m    124\u001b[39m )\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ethan\\.conda\\envs\\qargus\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     NaT,\n\u001b[32m      3\u001b[39m     Period,\n\u001b[32m      4\u001b[39m     Timedelta,\n\u001b[32m      5\u001b[39m     Timestamp,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NA\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ethan\\.conda\\envs\\qargus\\Lib\\site-packages\\pandas\\_libs\\__init__.py:16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas._libs.pandas_parser'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ethan\\.conda\\envs\\qargus\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1064\u001b[39m, in \u001b[36mfetch_openml\u001b[39m\u001b[34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)\u001b[39m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     \u001b[43mcheck_pandas_support\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m`fetch_openml`\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ethan\\.conda\\envs\\qargus\\Lib\\site-packages\\sklearn\\utils\\_optional_dependencies.py:46\u001b[39m, in \u001b[36mcheck_pandas_support\u001b[39m\u001b[34m(caller_name)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m requires pandas.\u001b[39m\u001b[33m\"\u001b[39m.format(caller_name)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: `fetch_openml` requires pandas.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mnist = \u001b[43mfetch_openml\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmnist_784\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_frame\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m X = mnist.data.astype(np.float32) / \u001b[32m255.0\u001b[39m\n\u001b[32m      3\u001b[39m y = mnist.target.astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ethan\\.conda\\envs\\qargus\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ethan\\.conda\\envs\\qargus\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1077\u001b[39m, in \u001b[36mfetch_openml\u001b[39m\u001b[34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)\u001b[39m\n\u001b[32m   1072\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1073\u001b[39m             err_msg = (\n\u001b[32m   1074\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing `parser=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparser\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m` with dense data requires pandas to be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1075\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minstalled. Alternatively, explicitly set `parser=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mliac-arff\u001b[39m\u001b[33m'\u001b[39m\u001b[33m`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1076\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1077\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(err_msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_sparse:\n\u001b[32m   1080\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m as_frame:\n",
      "\u001b[31mImportError\u001b[39m: Using `parser='auto'` with dense data requires pandas to be installed. Alternatively, explicitly set `parser='liac-arff'`."
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml(\"mnist_784\", version=1, as_frame=False)\n",
    "X = mnist.data.astype(np.float32) / 255.0\n",
    "y = mnist.target.astype(int)\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "train_idx = rng.choice(len(X), size=1000, replace=False)\n",
    "remaining = np.setdiff1d(np.arange(len(X)), train_idx, assume_unique=False)\n",
    "test_idx = rng.choice(remaining, size=128, replace=False)\n",
    "\n",
    "X_train = X[train_idx]\n",
    "y_train = y[train_idx]\n",
    "X_test = X[test_idx]\n",
    "y_test = y[test_idx]\n",
    "X_test_img = X_test.reshape(-1, 1, 28, 28)\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0])\n",
    "print(\"Test size:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8fb7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.000\n",
      "Test accuracy: 0.836\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(\n",
    "    loss=\"log_loss\",\n",
    "    fit_intercept=False,\n",
    "    max_iter=2000,\n",
    "    tol=1e-3,\n",
    "    random_state=0,\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_acc = np.mean(clf.predict(X_train) == y_train)\n",
    "test_acc = np.mean(clf.predict(X_test) == y_test)\n",
    "print(f\"Train accuracy: {train_acc:.3f}\")\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce8081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target digit: 3\n",
      "True count: 15\n",
      "Estimated count: 15\n",
      "Oracle queries (simulated): 63\n"
     ]
    }
   ],
   "source": [
    "config = QuantumResNetConfig(\n",
    "    input_shape=(1, 28, 28),\n",
    "    num_classes=10,\n",
    "    num_blocks=0,\n",
    "    channels=1,\n",
    "    kernel_size=1,\n",
    "    output_mode=\"classifier\",\n",
    ")\n",
    "model = QuantumResNet(config)\n",
    "load_sklearn_classifier(model, clf)\n",
    "\n",
    "preds = []\n",
    "quantum_logits = []\n",
    "for img in X_test_img:\n",
    "    result = model.forward(img)\n",
    "    quantum_logits.append(result.logits)\n",
    "    preds.append(int(np.argmax(result.probabilities)))\n",
    "\n",
    "target_digit = 3\n",
    "marks = [p == target_digit for p in preds]\n",
    "qc = estimate_count(marks, precision_bits=6)\n",
    "\n",
    "print(\"Target digit:\", target_digit)\n",
    "print(\"True count:\", qc.true_count)\n",
    "print(\"Estimated count:\", qc.estimated_count)\n",
    "print(\"Oracle queries (simulated):\", qc.oracle_queries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8698e8",
   "metadata": {},
   "source": [
    "## Deploy with semantic execution and QASM export\n",
    "\n",
    "Semantic execution runs the same pipeline without circuit synthesis.\n",
    "QASM export uses Qiskit/Aer to compile the unitary circuit for a concrete input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a902c73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic logits (L2-normalized): [-0.37091857 -0.2862483  -0.24978778 -0.20342551 -0.44136   ]\n",
      "Forward logits (L2-normalized): [-0.37091857 -0.2862483  -0.24978778 -0.20342551 -0.44136   ]\n",
      "Max diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "sample = X_test_img[0]\n",
    "semantic = run_semantic_model(model, sample)\n",
    "forward = model.forward(sample)\n",
    "\n",
    "print('Semantic logits (L2-normalized):', semantic.state[:5])\n",
    "print('Forward logits (L2-normalized):', forward.logits[:5])\n",
    "print('Max diff:', np.max(np.abs(semantic.state - forward.logits)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbe260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QASM export requires qiskit and qiskit-aer: qiskit and qiskit-aer are required for QASM export\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    qasm = model_to_qasm(model, input_state=sample, include_measurements=False)\n",
    "    qasm_path = ROOT / 'notebooks' / 'mnist10_semantic_unitary.qasm'\n",
    "    qasm_path.write_text(qasm)\n",
    "    print('Wrote QASM to:', qasm_path)\n",
    "    print(qasm.splitlines()[0])\n",
    "except ImportError as exc:\n",
    "    print('QASM export requires qiskit and qiskit-aer:', exc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec925ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum/classical agreement: 1.000\n",
      "Max logit diff (normalized): 0.000000\n",
      "0 7 7\n",
      "1 7 7\n",
      "2 3 3\n",
      "3 6 6\n",
      "4 2 2\n"
     ]
    }
   ],
   "source": [
    "def _l2_normalize_rows(arr):\n",
    "    norms = np.linalg.norm(arr, axis=1, keepdims=True)\n",
    "    return arr / np.clip(norms, 1e-12, None)\n",
    "\n",
    "X_test_norm = _l2_normalize_rows(X_test)\n",
    "classical_logits_raw = X_test_norm @ clf.coef_.T\n",
    "classical_logits = _l2_normalize_rows(classical_logits_raw)\n",
    "classical_preds = np.argmax(classical_logits, axis=1)\n",
    "\n",
    "agreement = np.mean(classical_preds == np.array(preds))\n",
    "max_logit_diff = np.max(np.abs(classical_logits - np.vstack(quantum_logits)))\n",
    "max_raw_diff = np.max(np.abs(classical_logits_raw - np.vstack(quantum_logits)))\n",
    "print(f\"Quantum/classical agreement: {agreement:.3f}\")\n",
    "print(f\"Max logit diff (normalized): {max_logit_diff:.6f}\")\n",
    "\n",
    "for i in range(5):\n",
    "    print(i, classical_preds[i], preds[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261e3c4e",
   "metadata": {},
   "source": [
    "## Resource estimation and advantage signals\n",
    "\n",
    "This section summarizes semantic execution metadata, circuit gate counts,\n",
    "and a classical baseline for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6812e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic uses: 1\n",
      "Semantic success prob: 1.0\n",
      "Ancilla peak (clean, dirty): 0 0\n",
      "Trace resource estimate: ResourceEstimate(ancilla_qubits_clean=0, ancilla_qubits_dirty=0, depth=0, one_qubit_gates=0, two_qubit_gates=0, t_count=0, measurements=0, qram_queries=0, oracle_queries=0, classical_queries=0, postselections=0)\n",
      "Classical MACs (linear head): 7840\n",
      "Classical count cost: 128 oracle calls\n",
      "Quantum counting oracle calls (simulated): 63\n",
      "Circuit resource estimation requires qiskit and qiskit-aer: No module named 'qiskit_aer'\n"
     ]
    }
   ],
   "source": [
    "sample = X_test_img[0]\n",
    "semantic = run_semantic_model(model, sample)\n",
    "forward = model.forward(sample)\n",
    "\n",
    "print('Semantic uses:', semantic.report.uses)\n",
    "print('Semantic success prob:', semantic.report.cumulative_success_prob)\n",
    "print('Ancilla peak (clean, dirty):', semantic.report.ancilla_clean_peak, semantic.report.ancilla_dirty_peak)\n",
    "print('Trace resource estimate:', forward.trace.resources)\n",
    "\n",
    "input_dim = int(np.prod(config.input_shape))\n",
    "classical_macs = input_dim * config.num_classes\n",
    "print('Classical MACs (linear head):', classical_macs)\n",
    "\n",
    "if 'qc' in globals():\n",
    "    print('Classical count cost:', len(preds), 'oracle calls')\n",
    "    print('Quantum counting oracle calls (simulated):', qc.oracle_queries)\n",
    "\n",
    "try:\n",
    "    from qargus import build_regime3_unitary_circuit\n",
    "    from qiskit import transpile\n",
    "    from qiskit_aer import Aer\n",
    "\n",
    "    circuit = build_regime3_unitary_circuit(model)\n",
    "    backend = Aer.get_backend('aer_simulator')\n",
    "    transpiled = transpile(circuit, backend=backend, optimization_level=1)\n",
    "    counts = transpiled.count_ops()\n",
    "    two_qubit = sum(counts.get(g, 0) for g in ('cx', 'cz', 'swap'))\n",
    "    print('Circuit depth:', transpiled.depth())\n",
    "    print('Two-qubit gates:', two_qubit)\n",
    "    print('Gate counts:', counts)\n",
    "except ImportError as exc:\n",
    "    print('Circuit resource estimation requires qiskit and qiskit-aer:', exc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qargus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
